{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6z/bh7_dtkj0c7dqhfn_nwgx23r0000gn/T/ipykernel_70218/2967216226.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_filtered['Cluster'] = kmeans.labels_\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "data = pd.read_excel('session.xlsx', parse_dates=['SESSION_END', 'SESSION_START'])\n",
    "\n",
    "# Remove sessions with a duration of 0 seconds\n",
    "data = data[data['SESSION_DURATION'] > 0]\n",
    "\n",
    "# Remove outliers using the IQR method\n",
    "Q1 = data['SESSION_DURATION'].quantile(0.25)\n",
    "Q3 = data['SESSION_DURATION'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "data_filtered = data[(data['SESSION_DURATION'] >= lower_bound) & (data['SESSION_DURATION'] <= upper_bound)]\n",
    "\n",
    "# Perform clustering analysis\n",
    "X = data_filtered['SESSION_DURATION'].values.reshape(-1, 1)\n",
    "kmeans = KMeans(n_clusters=4, random_state=42).fit(X)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "data_filtered['Cluster'] = kmeans.labels_\n",
    "\n",
    "df = data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6z/bh7_dtkj0c7dqhfn_nwgx23r0000gn/T/ipykernel_70218/4225386360.py:16: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  merged_data['NAVIGATION_PATH'] = merged_data['NAVIGATION_PATH'].apply(lambda x: ' -> '.join(pd.unique(x.split(' -> '))[:4]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Profiles/Personas:\n",
      "   Cluster  Total Sessions  Avg Session Duration Most Frequent Part  \\\n",
      "0        0       39.531250             72.356936              Tools   \n",
      "1        1       53.924138             17.043269              Tools   \n",
      "2        2       42.039735            268.396582              Tools   \n",
      "3        3       40.272277            160.835631              Tools   \n",
      "\n",
      "                                                                                    Most Common Navigation Path  \n",
      "0                     Mainpage -> List of active calendar tasks -> List of tools -> Tools: meal rhythm: choices  \n",
      "1                     Mainpage -> List of active calendar tasks -> List of tools -> Tools: meal rhythm: choices  \n",
      "2  Mainpage -> List of active calendar tasks -> List of tools -> Personal_resources_questionnaire: introduction  \n",
      "3            Mainpage -> List of tools -> Menu: health domain modules -> Stress_management: module introduction  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have the original dataset loaded into a DataFrame called 'data'\n",
    "# and the clustered data loaded into a DataFrame called 'df'\n",
    "\n",
    "# Merge the cluster information with the original dataset\n",
    "merged_data = pd.merge(data, df[['ID', 'SESSION', 'Cluster', 'SESSION_DURATION']], on=['ID', 'SESSION'])\n",
    "\n",
    "# Sort merged data by session and timestamp\n",
    "merged_data = merged_data.sort_values(by=['SESSION', 'TIMESTAMP'])\n",
    "\n",
    "# Create a navigation path for each session\n",
    "merged_data['NAVIGATION_PATH'] = merged_data.groupby('SESSION')['CURRENT'].transform(lambda x: ' -> '.join(x))\n",
    "\n",
    "# Limit the navigation path to a maximum depth of 10 different screens\n",
    "merged_data['NAVIGATION_PATH'] = merged_data['NAVIGATION_PATH'].apply(lambda x: ' -> '.join(pd.unique(x.split(' -> '))[:4]))\n",
    "\n",
    "# Analyze user behavior within each cluster\n",
    "user_behavior = merged_data.groupby(['ID', 'Cluster']).agg({\n",
    "    'SESSION': 'count',\n",
    "    'SESSION_DURATION': 'mean',\n",
    "    'PART': lambda x: x.mode().iloc[0] if not x.empty else None,\n",
    "    'NAVIGATION_PATH': lambda x: x.mode().iloc[0] if not x.empty else None\n",
    "}).reset_index()\n",
    "\n",
    "user_behavior.columns = ['ID', 'Cluster', 'Total Sessions', 'Avg Session Duration', 'Most Frequent Part', 'Most Common Navigation Path']\n",
    "\n",
    "# Identify user profiles or personas\n",
    "user_profiles = user_behavior.groupby('Cluster').agg({\n",
    "    'Total Sessions': 'mean',\n",
    "    'Avg Session Duration': 'mean',\n",
    "    'Most Frequent Part': lambda x: x.mode().iloc[0] if not x.empty else None,\n",
    "    'Most Common Navigation Path': lambda x: x.mode().iloc[0] if not x.empty else None\n",
    "}).reset_index()\n",
    "\n",
    "# Print the user profiles\n",
    "print(\"User Profiles/Personas:\")\n",
    "print(user_profiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
